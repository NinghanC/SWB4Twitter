{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c694ce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from scipy import sparse\n",
    "import csv\n",
    "import pickle\n",
    "from collections import Counter, OrderedDict\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import regex as re\n",
    "import statistics\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_stats(new_df, categoryname,textname,split_char=' '):\n",
    "    categories = new_df[categoryname].unique()\n",
    "    \n",
    "    all_lengths = []\n",
    "    per_category = {\n",
    "        'lengths': {c:[] for c in categories},\n",
    "        'mean': {c:0 for c in categories},\n",
    "        'stdev': {c:0 for c in categories}\n",
    "    }\n",
    "\n",
    "    for index, row in new_df.iterrows():\n",
    "        text = row[textname]\n",
    "        text = re.sub(r\"\\s+\", ' ', text) # Normalize\n",
    "        text = text.split(split_char)\n",
    "        l = len(text)\n",
    "        \n",
    "        category = row[categoryname]\n",
    "        \n",
    "        all_lengths.append(l)\n",
    "        per_category['lengths'][category].append(l)\n",
    "    \n",
    "    for c in categories:\n",
    "        per_category['mean'][c] = statistics.mean(per_category['lengths'][c])\n",
    "        per_category['stdev'][c] = statistics.stdev(per_category['lengths'][c])\n",
    "    \n",
    "    global_stats = {\n",
    "        'mean': statistics.mean(all_lengths),\n",
    "        'stdev': statistics.stdev(all_lengths),\n",
    "        'lengths': all_lengths\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'global': global_stats,\n",
    "        'per_category': pd.DataFrame(per_category)\n",
    "    }\n",
    "\n",
    "\n",
    "def display_lengths_histograms(df_stats, categoryname,n_cols=4):\n",
    "    categories = new_df[categoryname].unique()\n",
    "    n_rows = math.ceil(len(categories) / n_cols)\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.suptitle('Distribution of lengths')\n",
    "    \n",
    "    # Subplot of all lengths\n",
    "    plt.subplot(n_rows, n_cols, 1)\n",
    "    plt.title('All categories')\n",
    "    lengths = df_stats['global']['lengths']\n",
    "    plt.hist(lengths, color='r')\n",
    "\n",
    "    # Subplot of each category\n",
    "    index_subplot = 2\n",
    "    for c in categories:\n",
    "        plt.subplot(n_rows, n_cols, index_subplot)\n",
    "        plt.title('Category: %s' % c)\n",
    "        \n",
    "        lengths = df_stats['per_category']['lengths'][c]\n",
    "        plt.hist(lengths, color='b')\n",
    "\n",
    "        index_subplot += 1\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_categories(df,columnname,):\n",
    "    categories = df[[columnname]].values.reshape(-1)\n",
    "    counter_categories_cnt = Counter(categories)\n",
    "    counter_categories = OrderedDict(counter_categories_cnt.most_common())\n",
    "    category_names = counter_categories.keys()\n",
    "    category_values = counter_categories.values()\n",
    "\n",
    "    y_pos = np.arange(len(category_names))\n",
    "\n",
    "    plt.figure(1, figsize=(10, 5))\n",
    "    plt.bar(y_pos, category_values, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, category_names)\n",
    "    #plt.ylabel('Number of tweets')\n",
    "    plt.title('Distribution of tweets per language')\n",
    "    plt.gca().yaxis.grid(True)\n",
    "    plt.show()\n",
    "    print(counter_categories)\n",
    "    return counter_categories\n",
    "\n",
    "\n",
    "def print_info_df(df_final_in):\n",
    "    \"\"\"\n",
    "    print information\n",
    "    \"\"\"\n",
    "    df_final_in_user = df_final_in.drop_duplicates(subset=['retweet_user'], keep='last')\n",
    "    print('number of retweet users',len(df_final_in_user)) \n",
    "    df_final_in_org_user = df_final_in.drop_duplicates(subset=['org_user'], keep='last')\n",
    "    print('number of orignal users',len(df_final_in_org_user))\n",
    "    df_final_in_tweet = df_final_in.drop_duplicates(subset=['org_id'], keep='last')\n",
    "    print('number of orignal tweets',len(df_final_in_tweet))\n",
    "    print('number of tweets',len(df_final_in))\n",
    "    \n",
    "def swb_calucation(df):\n",
    "    swb_dict = {}\n",
    "    for i in tqdm(df['user_id']):\n",
    "        a = df[df['user_id'] == i]\n",
    "        #print(a)\n",
    "        P = len(a[a['new_senti_label'] == 'Positive'])\n",
    "        #print(P)\n",
    "        N = len(a[a['new_senti_label'] == 'Negative'])\n",
    "        #print(N)\n",
    "        Ne = len(a[a['new_senti_label'] == 'Neutral'])\n",
    "        #print(Ne)\n",
    "        SWB = ((P - N)/(P + N))*cmath.sqrt((P+N)/(P+N+Ne))\n",
    "        # print(SWB)\n",
    "        swb_dict[str(i)] = SWB\n",
    "    return swb_dict\n",
    "\n",
    "def read_file(path,file_name):\n",
    "    df = pd.read_pickle(path + 'cleaned-'+file_name)\n",
    "    df['text_id'] = df['text_id'].map(lambda x :str(x))\n",
    "    df['retweet_id'] = df['retweet_id'].map(lambda x :str(x))\n",
    "    df['retweet_user_id'] = df['retweet_user_id'].map(lambda x :str(x))\n",
    "    df['retweet_text'] = df['retweet_text'].map(lambda x :str(x))\n",
    "    final_text = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        if df.iloc[i]['retweet_status'] == '0':\n",
    "            final_text.append(df.iloc[i]['text'])\n",
    "        if df.iloc[i]['retweet_status'] == '1':\n",
    "            final_text.append(df.iloc[i]['retweet_text'])\n",
    "    df['final_text'] = final_text\n",
    "    org_id = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        if df.iloc[i]['retweet_status'] == '0':\n",
    "            org_id.append(df.iloc[i]['text_id'])\n",
    "        if df.iloc[i]['retweet_status'] == '1':\n",
    "            org_id.append(df.iloc[i]['retweet_id'])\n",
    "    df['org_id'] = org_id\n",
    "    df = df.drop_duplicates(subset = ['org_id'], keep='last').reset_index(drop=True)\n",
    "    print(len(df))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7625e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
